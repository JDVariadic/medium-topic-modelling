---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
library(tidyverse)
library(tidytext)
library(wordcloud2)
library(igraph)
library(ggraph)
library(widyr)
library(topicmodels)
library(quanteda)

#https://stackoverflow.com/questions/23479512/stratified-random-sampling-from-data-frame by user A5C1D2H2I1M1N2O1R2T1
#Didn't actually use for research, just for testing
library(splitstackshape)
set.seed(1)
```

```{r}
#Read the pre-processed data.
data <- read.csv('medium_english_data_formatted_v3.csv', encoding="UTF-8")
#data <- stratified(data, c('month', 'tag'), .25)
text_df <- as_tibble(data)
```

```{r}
#Use relevant columns for topic modelling.
filtered_data <- text_df[,c('post_id', 'article_title', 'text_data')] 
```

```{r}
#Manually remove other stopwords and common terms
other_words <- list('medium', 'mediumget', 'www', 'don', 'followersaboutget', 'app', 'min', 'startedopen', 'coronavirus', 'covid', 'virus', 'followersaboutfollowsign', '2020medium', '200a', 'aren', 'de', 've', '11', 'll', 'ann', 'isn', 'doesn', 'didn', 'more.medium', 'mediumabouthelplegalget', 'yours.follow', 'mediumsign', 'covid19', '2020', 'moremake', 'health', 'wasn', 'couldn', 'covid-19', 'people')
```

```{r}
#Create a corpus object using the datset
medium_corpus <- corpus(filtered_data$text_data, docnames = filtered_data$post_id)
medium_corpus
```

```{r}
#Tokenize corpus and use patterns to filter stopwords and other common words that may affect the topic model.
corpus_tokens <- medium_corpus %>% 
  tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>% 
  tokens_tolower() %>%
  tokens_remove(stop_words$word)%>%
  tokens_remove(other_words)
```

```{r}
#Exclude words that do not appear as much as the others to decrease filesize.
trimmed_dtm <- corpus_tokens %>%
  dfm() %>%
  dfm_trim(min_docfreq = 0.01, max_docfreq=Inf, docfreq_type='prop')

save(trimmed_dtm, file='trimmed_dtm.RData')
```

```{r}
#Variables list has trimmed_dtm variable which is needed for LDA modelling. Used only to load variables from previous sessions. No need to run if you're running the code from top to bottom in one go.
#load('RDATA FILES/full_topic_30_lda_model_variables.RData')
```

```{r}
#Topic Modelling, edited iteration hyperparameter. Verbosity just gives the progress of iterations.
#topic_model_40 <- LDA(trimmed_dtm, 40, method="Gibbs", control=list(iter = 1000, seed = 1, verbose = 200))
```
```{r}
#Save topic into RData format to be loaded in another file for visualizations.
#save(topic_model_40, file='full_topic_model_40.RData')
```
```{r}
trimmed_dtm
```




Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.